{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mnist_plus_template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FCUAIC/Basic-ML/blob/main/mnist_plus_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkJe9oRX0xHP"
      },
      "source": [
        "# MNIST Plus Template\n",
        "\n",
        "作者: 梁定殷\n",
        "\n",
        "版權歸FCUAI所有"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAP_RwwR0xHZ"
      },
      "source": [
        "Input shape: (1, 28, 28)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QP0h2hz0xHa"
      },
      "source": [
        "## 超參數(Hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_30N5F-0xHc"
      },
      "source": [
        "# 學習率(Learning Rate), LR越大模型越有自信, LR越小模型越沒自信\n",
        "LR = 0.01\n",
        "# 每次學習要看過多少的Batch後才更新模型\n",
        "BATCH_SIZE = 1024\n",
        "# 學習次數\n",
        "EPOCHS = 10\n",
        "\n",
        "用離線的MNIST = True # Pytorch的MNIST暫時不能用"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsaQUcdrzICn"
      },
      "source": [
        "## 載入需要用的Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7YoBf-40xHe"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adadelta\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchsummary import summary\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "if 用離線的MNIST:\n",
        "    from keras.datasets import mnist\n",
        "else:\n",
        "    from torchvision.datasets import MNIST\n",
        "\n",
        "\n",
        "from sklearn.model_selection import  train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm.notebook import trange, tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHtR-7Vi0xHf"
      },
      "source": [
        "## 模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wset3Ml-0xHf"
      },
      "source": [
        "class MNISTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            # in: 1x28x28\n",
        "            nn.Conv2d(in_channels=1,\n",
        "                      out_channels=32,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=?\n",
        "                    ),\n",
        "            nn.ReLU(),\n",
        "            # in: 32x?x?\n",
        "            nn.MaxPool2D(?),\n",
        "\n",
        "            # in: 32x?x?\n",
        "            nn.Conv2d(in_channels=32,\n",
        "                      out_channels=64,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=?\n",
        "                    ),\n",
        "            nn.Dropout(),\n",
        "            nn.ReLU(),\n",
        "            # in: 64x?x?\n",
        "            nn.Flatten(),\n",
        "            # out: ?\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features=?, out_features=1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=1024, out_features=10),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "model = MNISTModel().cuda()\n",
        "summary(model, (1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxUV8qwb0xHi"
      },
      "source": [
        "## 資料集(Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx9x2weMkazV"
      },
      "source": [
        "class MNISTDataset(Dataset):\n",
        "    \"\"\"\n",
        "        這是我們定義的Dataset\n",
        "    \"\"\"\n",
        "    def __init__(self, train=False, transformer=None):\n",
        "        # 從Keras載入MNIST\n",
        "        (train_feature, train_label), (test_feature, test_label) = mnist.load_data()\n",
        "        if train:\n",
        "            # 我們只要訓練的\n",
        "            self.data = np.array([list(d) for d in zip(train_feature, train_label)], dtype=object)\n",
        "            self.length = len(train_feature)\n",
        "        else:\n",
        "            # 我們只要測試的\n",
        "            self.data = np.array([list(d) for d in zip(test_feature, test_label)], dtype=object)\n",
        "            self.length = len(test_feature)\n",
        "        \n",
        "        self.transformer = transformer\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 對data做轉換\n",
        "        if self.transformer:\n",
        "            img, label = self.data[idx]\n",
        "            return self.transformer(img), torch.tensor(label, dtype=torch.long)\n",
        "        return self.data[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJS4gVRJzZfC"
      },
      "source": [
        "## 載入資料集(Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kgkgAAz0xHk"
      },
      "source": [
        "preprocessor = transforms.Compose([\n",
        "    transforms.ToTensor() #轉成Tensor的時候會做歸一化(Normalize)\n",
        "    ])\n",
        "\n",
        "\n",
        "if 用離線的MNIST:\n",
        "    print('使用離線的Dataset.')\n",
        "    mnist_train = MNISTDataset(train=True, transformer=preprocessor)\n",
        "    mnist_test = MNISTDataset(train=False, transformer=preprocessor)\n",
        "else:\n",
        "    print('使用Pytorch的Dataset.')\n",
        "    mnist_train = MNIST(root='mnist', download=True, transform=preprocessor, train=True)\n",
        "    mnist_test = MNIST(root='mnist', transform=preprocessor, train=False)\n",
        "\n",
        "print(f'訓練資料一共有{len(mnist_train)}筆資料\\n測試資料一共有{len(mnist_test)}筆資料')\n",
        "\n",
        "\n",
        "mnist_train = DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=True) # 我們想要打散訓練資料的順序\n",
        "mnist_test = DataLoader(mnist_test, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rcXU1xC07x_"
      },
      "source": [
        "## 來看一下我們的資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMOy_zkY07IC"
      },
      "source": [
        "if 用離線的MNIST:\n",
        "    preview_train = MNISTDataset(train=True)\n",
        "else:\n",
        "    preview_train = MNIST(root='mnist', download=True, transform=None, train=True)\n",
        "\n",
        "# 實作一: 完成這個功能\n",
        "indexs = [-1] * 10\n",
        "# 找出第一個0-9在dataset裡的位置\n",
        "for i, batch in enumerate(preview_train):\n",
        "    # 把一個batch拆開, img是圖片, label是圖片的數字\n",
        "    img, label = batch\n",
        "    # 在這裡開始寫\n",
        "    \n",
        "# 輸出結果\n",
        "for num, idx in enumerate(indexs):\n",
        "    print(f'第一張數字 {num}的圖片出現在dataset的第 {idx}個位置')\n",
        "print(indexs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTHBsDv_pVy-"
      },
      "source": [
        "for idx in indexs:\n",
        "    img, label = preview_train[idx]\n",
        "    plt.title(f'label: {label}')\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ADYeFqd0xHl"
      },
      "source": [
        "## 宣告損失函數&優化器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSitIE8s0xHm"
      },
      "source": [
        "# 計算輸出的損失函數(Loss function)\n",
        "loss_func = CrossEntropyLoss() # 計算機率的Loss我們會用交叉熵(CrossEntropy)\n",
        "# 這是優化器(Optimizer), 使得模型能更好的學習, 可以想成是學習的策略\n",
        "optimizer = Adadelta(model.parameters(), lr=LR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR-qq2dy0xHp"
      },
      "source": [
        "## 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jbgexbD0xHq"
      },
      "source": [
        "# 把每個EPOCH的Loss記錄下來\n",
        "losses_log = []\n",
        "# 開始訓練\n",
        "for epoch in trange(1, EPOCHS+1, desc='Epoch', unit='次'):\n",
        "    # 忘記剛才學習的方向\n",
        "    losses = 0\n",
        "    optimizer.zero_grad()\n",
        "    # 給模型看很多的圖\n",
        "    for batch_x, batch_y in tqdm(mnist_train, desc='訓練進度', unit='batch'):\n",
        "        # 把圖跟答案放到GPU\n",
        "        x = batch_x.cuda()\n",
        "        y = batch_y.cuda()\n",
        "        # 問模型這是什麼\n",
        "        predict = model(x)\n",
        "        # 根據模型的回答評分\n",
        "        loss = loss_func(predict, y)\n",
        "        # 告訴模型哪裡錯了\n",
        "        loss.backward()\n",
        "        # 把所有錯的地方跟程度加起來\n",
        "        losses += loss.item()\n",
        "        # 模型根據上面給的方向學習\n",
        "        optimizer.step()\n",
        "    \n",
        "\n",
        "    # 測試, 給模型看從沒看過的圖, 看他是真懂還是假懂\n",
        "    test_losses = 0\n",
        "    trues = []\n",
        "    predicts = []\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in tqdm(mnist_test, desc='測試進度', unit='張'):\n",
        "            x = batch_x.cuda()\n",
        "            y = batch_y.cuda()\n",
        "\n",
        "            predict = model(x)\n",
        "            test_losses += loss_func(predict, y).item()\n",
        "            # 選模型認為最有可能的數字\n",
        "            predict = torch.argmax(predict, dim=1, keepdim=True)\n",
        "            trues += y.tolist()\n",
        "            predicts += predict.tolist()\n",
        "        # 記錄Loss\n",
        "        losses_log.append(test_losses)\n",
        "        # 印出這次Epoch的總結與統計\n",
        "        print(f'EPOCH {epoch} | 訓練資料的Loss: {losses/len(mnist_train.dataset)} | 測試資料的Loss: {test_losses/len(mnist_test.dataset)}\\n{classification_report(trues, predicts, labels=[l for l in range(0, 10)], digits=4)}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oePcbffY-DfY"
      },
      "source": [
        "## 把訓練過程的Loss 畫出來"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCVX9rRRz4y6"
      },
      "source": [
        "# X 軸是Epoch, Y 是對應Epoch 的Loss\n",
        "plt.plot(list(range(1, EPOCHS+1)), losses_log)\n",
        "plt.xticks(list(range(1, EPOCHS+1)))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlim(1, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}